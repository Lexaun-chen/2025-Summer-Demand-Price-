{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import connectorx as cx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "def process_single_date(trading_date, output_dir):\n",
    "    \"\"\"处理单个交易日的函数\"\"\"\n",
    "    \n",
    "    date_str = trading_date.strftime('%Y%m%d')\n",
    "    one_min_pth = f\"/data/HighFreqData/MinuteQuote/new_minute/one_minute/{date_str}.parquet\"\n",
    "    output_file = f\"{output_dir}/{date_str}_limit_stocks.parquet\"\n",
    "    \n",
    "    # 如果该日期的文件已存在，跳过处理\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"日期 {date_str} 已处理，跳过\")\n",
    "        return date_str, True, 0  # 返回日期、成功标志和处理的股票数\n",
    "    \n",
    "    if not os.path.exists(one_min_pth):\n",
    "        print(f\"数据文件不存在: {one_min_pth}\")\n",
    "        return date_str, False, 0\n",
    "    \n",
    "    # 格式化日期为SQL查询格式\n",
    "    sql_date = trading_date.strftime('%Y-%m-%d')\n",
    "    conn_str = \"mysql://lexuan_chen%40public%23Thetis:OWFF4UT!@192.168.55.161:2883/jydb\"\n",
    "\n",
    "    # 获取所有交易日的涨跌停信息\n",
    "    sql_query1 = f\"\"\"\n",
    "    SELECT \n",
    "        InnerCode,\n",
    "        TradingDay as trading_day,\n",
    "        PriceCeiling as price_ceiling,\n",
    "        PriceFloor as price_floor\n",
    "    FROM jydb.DZ_PriceLimit \n",
    "    WHERE DATE(TradingDay) = '{sql_date}'\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query2 = f\"\"\"\n",
    "    SELECT \n",
    "        InnerCode,\n",
    "        SecuCode AS security_code,\n",
    "        TradingDay as trading_day\n",
    "    FROM smartquant.ReturnDaily \n",
    "    WHERE DATE(TradingDay) = '{sql_date}'\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        daily_limit_df = cx.read_sql(conn_str, sql_query1)\n",
    "        code_df = cx.read_sql(conn_str, sql_query2)\n",
    "        \n",
    "        daily_limit_df['trading_day'] = pd.to_datetime(daily_limit_df['trading_day'])\n",
    "        code_df['trading_day'] = pd.to_datetime(code_df['trading_day'])\n",
    "\n",
    "        daily_limit_df = pd.merge(daily_limit_df, code_df, on=['InnerCode','trading_day'], how='left')\n",
    "\n",
    "        if daily_limit_df.empty:\n",
    "            print(f\"日期 {date_str} 没有涨跌停信息\")\n",
    "            return date_str, False, 0\n",
    "        \n",
    "        # 为每个进程创建独立的duckdb连接\n",
    "        conn = duckdb.connect(database=':memory:')\n",
    "        \n",
    "        query_minute = f\"\"\"\n",
    "        SELECT \n",
    "            security_code,\n",
    "            MAX(high_price) AS high_price,\n",
    "            MIN(low_price) AS low_price\n",
    "        FROM '{one_min_pth}' \n",
    "        WHERE start_time < 1030\n",
    "          AND start_time >= 930\n",
    "        GROUP BY security_code \n",
    "        \"\"\"\n",
    "        \n",
    "        early_mins = conn.execute(query_minute).fetchdf()\n",
    "        \n",
    "        if early_mins.empty:\n",
    "            print(f\"日期 {date_str} 没有符合条件的分钟数据\")\n",
    "            conn.close()\n",
    "            return date_str, False, 0\n",
    "        \n",
    "        # 确保security_code列存在且不为空\n",
    "        daily_limit_df = daily_limit_df.dropna(subset=['security_code'])\n",
    "        \n",
    "        limit_dict = dict(zip(daily_limit_df['security_code'], \n",
    "                            zip(daily_limit_df['price_ceiling'], daily_limit_df['price_floor'])))\n",
    "\n",
    "        # 存储当日达到涨跌停的股票\n",
    "        daily_limit_stocks = []\n",
    "\n",
    "        # 检查哪些股票在时段内达到过涨跌停价格\n",
    "        for security_code, group in early_mins.groupby('security_code'):  # 修正变量名\n",
    "            if security_code in limit_dict:\n",
    "                price_ceiling, price_floor = limit_dict[security_code]\n",
    "                \n",
    "                # 检查是否有价格达到涨跌停\n",
    "                if (group['high_price'] >= price_ceiling).any() or (group['low_price'] <= price_floor).any():\n",
    "                    daily_limit_stocks.append(security_code)\n",
    "        \n",
    "        # 如果有股票达到涨跌停，保存到当日文件\n",
    "        if daily_limit_stocks:\n",
    "            limit_stocks_df = pd.DataFrame({\n",
    "                'date': [trading_date] * len(daily_limit_stocks),\n",
    "                'security_code': daily_limit_stocks\n",
    "            })\n",
    "            limit_stocks_df.to_parquet(output_file)\n",
    "            print(f\"日期 {date_str} 处理完成，标记了 {len(daily_limit_stocks)} 只股票\")\n",
    "            conn.close()\n",
    "            return date_str, True, len(daily_limit_stocks)\n",
    "        else:\n",
    "            # 创建空文件表示已处理但没有符合条件的股票\n",
    "            pd.DataFrame(columns=['date', 'security_code']).to_parquet(output_file)\n",
    "            print(f\"日期 {date_str} 处理完成，没有股票达到涨跌停\")\n",
    "            conn.close()\n",
    "            return date_str, True, 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理日期 {date_str} 时出错: {e}\")\n",
    "        traceback.print_exc()  # 打印详细错误信息\n",
    "        return date_str, False, 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    start_date = '2021-05-18'  \n",
    "    end_date = '2024-12-31'    \n",
    "\n",
    "    trading_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "    factor_path = \"/data/home/lexuanchen/Factors/Order/Signal/early_order_size_ratio.csv\"\n",
    "    factor_df = pd.read_csv(factor_path)\n",
    "\n",
    "    factor_df['date'] = pd.to_datetime(factor_df['date'])\n",
    "\n",
    "    output_dir = \"./factors/limit_stocks_daily\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    num_processes = 10\n",
    "\n",
    "    print(f\"使用 {num_processes} 个进程进行并行处理\")\n",
    "\n",
    "    # 创建进程池\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    \n",
    "    # 创建带有固定参数的函数\n",
    "    process_date_with_args = partial(\n",
    "        process_single_date,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 提交所有任务到进程池\n",
    "    results = pool.map(process_date_with_args, trading_dates)\n",
    "    \n",
    "    # 关闭进程池\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    processed_dates = [date_str for date_str, success, _ in results if success]\n",
    "    processed_count = len(processed_dates)\n",
    "    total_count = len(trading_dates)\n",
    "    \n",
    "    print(f\"已处理 {processed_count}/{total_count} 个交易日 ({processed_count/total_count*100:.2f}%)\")\n",
    "\n",
    "    print(\"开始合并所有日期的结果...\")\n",
    "    all_files = glob.glob(f\"{output_dir}/*_limit_stocks.parquet\")\n",
    "    all_limit_stocks = []\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            if not df.empty:\n",
    "                all_limit_stocks.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {file} 时出错: {e}\")\n",
    "\n",
    "    if all_limit_stocks:\n",
    "        # 合并所有日期的数据\n",
    "        mark_df = pd.concat(all_limit_stocks, ignore_index=True)\n",
    "        \n",
    "        # 标记因子值为NaN\n",
    "        factor_df['security_code'] = factor_df['security_code'].astype(str)\n",
    "        mark_df['security_code'] = mark_df['security_code'].astype(str)\n",
    "\n",
    "        factor_df = factor_df.merge(\n",
    "            mark_df.assign(to_mark=True),\n",
    "            on=['date', 'security_code'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        marked_count = factor_df['to_mark'].sum()\n",
    "        factor_df.loc[factor_df['to_mark'] == True, 'early_order_size_ratio'] = np.nan\n",
    "        \n",
    "        factor_df = factor_df.drop('to_mark', axis=1)\n",
    "\n",
    "        print(f\"共标记了 {marked_count} 个涨跌停股票的因子值为NaN\")\n",
    "\n",
    "        new_factor_path = \"/data/home/lexuanchen/Factors/Order/Signal/hl_early_order_size_ratio.csv\"\n",
    "        factor_df.to_csv(new_factor_path, index=False)\n",
    "        print(f\"已将更新后的因子数据保存到 {new_factor_path}\")\n",
    "    else:\n",
    "        print(\"没有找到需要标记为NaN的股票\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"总运行时间: {(end_time - start_time)/60:.2f} 分钟\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共标记了 37886 个涨跌停股票的因子值为NaN\n",
      "已将更新后的因子数据保存到 /data/home/lexuanchen/Factors/Order/Signal/hl_residual_early_order_size_ratio.csv\n"
     ]
    }
   ],
   "source": [
    "#把每天的因子值和同时间段的收益率回归取残差 \n",
    "def derive_hl_ret_factor():\n",
    "    factor_name = \"early_order_size_ratio\"\n",
    "    output_dir = \"./factors/limit_stocks_daily\"\n",
    "    all_files = glob.glob(f\"{output_dir}/*_limit_stocks.parquet\")\n",
    "    all_limit_stocks = []\n",
    "\n",
    "    factor_path = \"/data/home/lexuanchen/Factors/Order/Signal\"\n",
    "    factor_dir = f\"{factor_path}/residual_{factor_name}.csv\"\n",
    "    factor_df = pd.read_csv(factor_dir)\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            if not df.empty:\n",
    "                all_limit_stocks.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {file} 时出错: {e}\")\n",
    "\n",
    "    if all_limit_stocks:\n",
    "        \n",
    "        # 合并所有日期的数据\n",
    "        mark_df = pd.concat(all_limit_stocks, ignore_index=True)\n",
    "        \n",
    "        # 确保两个数据框中的日期列都是相同的类型(datetime64[ns])\n",
    "        factor_df['date'] = pd.to_datetime(factor_df['date'])\n",
    "        mark_df['date'] = pd.to_datetime(mark_df['date'])\n",
    "        \n",
    "        # 确保security_code列都是字符串类型\n",
    "        factor_df['security_code'] = factor_df['security_code'].astype(str)\n",
    "        mark_df['security_code'] = mark_df['security_code'].astype(str)\n",
    "\n",
    "        factor_df = factor_df.merge(\n",
    "            mark_df.assign(to_mark=True),\n",
    "            on=['date', 'security_code'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        marked_count = factor_df['to_mark'].sum()\n",
    "        factor_df.loc[factor_df['to_mark'] == True, 'residual_factor'] = np.nan\n",
    "        \n",
    "        factor_df = factor_df.drop('to_mark', axis=1)\n",
    "\n",
    "        print(f\"共标记了 {marked_count} 个涨跌停股票的因子值为NaN\")\n",
    "\n",
    "        new_factor_path = f\"{factor_path}/hl_residual_early_order_size_ratio.csv\"\n",
    "        factor_df.to_csv(new_factor_path, index=False)\n",
    "        print(f\"已将更新后的因子数据保存到 {new_factor_path}\")\n",
    "\n",
    "    \n",
    "    return factor_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    derive_hl_ret_factor()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
