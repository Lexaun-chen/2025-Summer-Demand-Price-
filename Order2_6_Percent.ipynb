{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import connectorx as cx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_factor(trading_date):\n",
    "    date_str = pd.to_datetime(trading_date).strftime('%Y%m%d')\n",
    "    order_pth = f\"/data/cephfs/order/{date_str}.parquet\"\n",
    "\n",
    "    \n",
    "    conn = duckdb.connect(database=':memory:')\n",
    "\n",
    "    # 定义六个时间段的查询\n",
    "    time_intervals = {\n",
    "        'pre_open_915_920': \"order_time >= 91500000 AND order_time < 92000000\",\n",
    "        'pre_open_920_925': \"order_time >= 92000000 AND order_time < 92500000\",\n",
    "        'early_930_1000': \"order_time >= 93000000 AND order_time < 100000000\",\n",
    "        'main_1000_1430': \"order_time >= 100000000 AND order_time < 143000000\",\n",
    "        'late_1430_1457': \"order_time >= 143000000 AND order_time < 145700000\",\n",
    "        'close_1457_1500': \"order_time >= 145700000 AND order_time < 150000000\",\n",
    "        'continue_930_1457':\"order_time >= 93000000 AND order_time < 145700000\"\n",
    "    }\n",
    "\n",
    "    # 创建的表名列表\n",
    "    created_tables = []\n",
    "    \n",
    "    # 分位数类型列表\n",
    "    percentile_types = ['p01_p99', 'p05_p95']\n",
    "\n",
    "    try:\n",
    "        # 为每个时间段和买卖方向创建临时表\n",
    "        for interval_name, time_condition in time_intervals.items():\n",
    "            # 买方订单\n",
    "            bid_query = f\"\"\"\n",
    "            SELECT \n",
    "                security_code,\n",
    "                order_side, \n",
    "                order_type,\n",
    "                order_details,\n",
    "                order_price,\n",
    "                order_price_adj,\n",
    "                order_volume,\n",
    "                order_time\n",
    "            FROM '{order_pth}'\n",
    "            WHERE order_type = 'A'\n",
    "                AND order_details = 'L'\n",
    "                AND order_side = 1\n",
    "                AND {time_condition}\n",
    "                AND order_price > 0\n",
    "            \"\"\"\n",
    "            \n",
    "            # 卖方订单\n",
    "            ask_query = f\"\"\"\n",
    "            SELECT \n",
    "                security_code,\n",
    "                order_side, \n",
    "                order_type,\n",
    "                order_details,\n",
    "                order_price,\n",
    "                order_price_adj,\n",
    "                order_volume,\n",
    "                order_time\n",
    "            FROM '{order_pth}'\n",
    "            WHERE order_type = 'A'\n",
    "                AND order_details = 'L'\n",
    "                AND order_side = -1\n",
    "                AND {time_condition}\n",
    "                AND order_price > 0\n",
    "            \"\"\"\n",
    "            \n",
    "            # 检查买方订单是否有数据\n",
    "            check_bid_query = f\"\"\"\n",
    "            SELECT COUNT(*) AS count FROM ({bid_query}) t\n",
    "            \"\"\"\n",
    "            bid_count = conn.execute(check_bid_query).fetchone()[0]\n",
    "            \n",
    "            if bid_count > 0:\n",
    "                # 创建买方基础表\n",
    "                conn.execute(f\"CREATE TEMPORARY TABLE bid_base_{interval_name} AS {bid_query}\")\n",
    "                \n",
    "                # 计算买方价格分位数\n",
    "                bid_percentile_query = f\"\"\"\n",
    "                CREATE TEMPORARY TABLE bid_percentiles_{interval_name} AS\n",
    "                SELECT \n",
    "                    security_code,\n",
    "                    PERCENTILE_CONT(0.03) WITHIN GROUP (ORDER BY order_price) AS p03,\n",
    "                    PERCENTILE_CONT(0.97) WITHIN GROUP (ORDER BY order_price) AS p97,\n",
    "\n",
    "                FROM bid_base_{interval_name}\n",
    "                GROUP BY security_code\n",
    "                \"\"\"\n",
    "                conn.execute(bid_percentile_query)\n",
    "                \n",
    "                # 创建买方P01-P99缩尾表\n",
    "                bid_winsorized_query_p03_p97 = f\"\"\"\n",
    "                CREATE TEMPORARY TABLE bid_{interval_name}_p03_p97 AS\n",
    "                SELECT \n",
    "                    b.security_code,\n",
    "                    b.order_side,\n",
    "                    b.order_type,\n",
    "                    b.order_details,\n",
    "                    CASE \n",
    "                        WHEN b.order_price < p.p03 THEN p.p03\n",
    "                        WHEN b.order_price > p.p97 THEN p.p97\n",
    "                        ELSE b.order_price\n",
    "                    END AS order_price,\n",
    "                    b.order_price_adj,\n",
    "                    b.order_volume,\n",
    "                    b.order_time\n",
    "                FROM bid_base_{interval_name} b\n",
    "                JOIN bid_percentiles_{interval_name} p ON b.security_code = p.security_code\n",
    "                \"\"\"\n",
    "                conn.execute(bid_winsorized_query_p03_p97)\n",
    "                created_tables.append(f'bid_{interval_name}_p03_p97')\n",
    "                \n",
    "            \n",
    "            # 检查卖方订单是否有数据\n",
    "            check_ask_query = f\"\"\"\n",
    "            SELECT COUNT(*) AS count FROM ({ask_query}) t\n",
    "            \"\"\"\n",
    "            ask_count = conn.execute(check_ask_query).fetchone()[0]\n",
    "            \n",
    "            if ask_count > 0:\n",
    "                # 创建卖方基础表\n",
    "                conn.execute(f\"CREATE TEMPORARY TABLE ask_base_{interval_name} AS {ask_query}\")\n",
    "                \n",
    "                # 计算卖方价格分位数\n",
    "                ask_percentile_query = f\"\"\"\n",
    "                CREATE TEMPORARY TABLE ask_percentiles_{interval_name} AS\n",
    "                SELECT \n",
    "                    security_code,\n",
    "                    PERCENTILE_CONT(0.03) WITHIN GROUP (ORDER BY order_price) AS p03,\n",
    "                    PERCENTILE_CONT(0.97) WITHIN GROUP (ORDER BY order_price) AS p97,\n",
    "\n",
    "                FROM ask_base_{interval_name}\n",
    "                GROUP BY security_code\n",
    "                \"\"\"\n",
    "                conn.execute(ask_percentile_query)\n",
    "                \n",
    "                # 创建卖方P01-P99缩尾表\n",
    "                ask_winsorized_query_p03_p97 = f\"\"\"\n",
    "                CREATE TEMPORARY TABLE ask_{interval_name}_p03_p97 AS\n",
    "                SELECT \n",
    "                    a.security_code,\n",
    "                    a.order_side,\n",
    "                    a.order_type,\n",
    "                    a.order_details,\n",
    "                    CASE \n",
    "                        WHEN a.order_price < p.p03 THEN p.p03\n",
    "                        WHEN a.order_price > p.p97 THEN p.p97\n",
    "                        ELSE a.order_price\n",
    "                    END AS order_price,\n",
    "                    a.order_price_adj,\n",
    "                    a.order_volume,\n",
    "                    a.order_time\n",
    "                FROM ask_base_{interval_name} a\n",
    "                JOIN ask_percentiles_{interval_name} p ON a.security_code = p.security_code\n",
    "                \"\"\"\n",
    "                conn.execute(ask_winsorized_query_p03_p97)\n",
    "                created_tables.append(f'ask_{interval_name}_p03_p97')\n",
    "                \n",
    "                # # 创建卖方P05-P95缩尾表\n",
    "                # ask_winsorized_query_p05_p95 = f\"\"\"\n",
    "                # CREATE TEMPORARY TABLE ask_{interval_name}_p05_p95 AS\n",
    "                # SELECT \n",
    "                #     a.security_code,\n",
    "                #     a.order_side,\n",
    "                #     a.order_type,\n",
    "                #     a.order_details,\n",
    "                #     CASE \n",
    "                #         WHEN a.order_price < p.p05 THEN p.p05\n",
    "                #         WHEN a.order_price > p.p95 THEN p.p95\n",
    "                #         ELSE a.order_price\n",
    "                #     END AS order_price,\n",
    "                #     a.order_price_adj,\n",
    "                #     a.order_volume,\n",
    "                #     a.order_time\n",
    "                # FROM ask_base_{interval_name} a\n",
    "                # JOIN ask_percentiles_{interval_name} p ON a.security_code = p.security_code\n",
    "                # \"\"\"\n",
    "                # conn.execute(ask_winsorized_query_p05_p95)\n",
    "                # created_tables.append(f'ask_{interval_name}_p05_p95')\n",
    "\n",
    "        # 计算所有因子\n",
    "        result_df = None\n",
    "        \n",
    "        for factor_name in created_tables:\n",
    "            # 提取时间段和分位数类型\n",
    "            parts = factor_name.split('_')\n",
    "            side = parts[0]  # bid 或 ask\n",
    "            interval_name = '_'.join(parts[1:-2])  # 时间段名称\n",
    "            percentile_type = parts[-2] + '_' + parts[-1]  # p03_p97 \n",
    "            \n",
    "            # 检查表是否有足够的数据计算因子\n",
    "            check_query = f\"\"\"\n",
    "            SELECT COUNT(*) AS count FROM {factor_name} \n",
    "            WHERE order_price IS NOT NULL\n",
    "            \"\"\"\n",
    "            count = conn.execute(check_query).fetchone()[0]\n",
    "            \n",
    "            if count <= 1:  # 需要至少两条记录才能计算分歧度\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # 计算订单加权平均对数价格\n",
    "                factor_query = f\"\"\"\n",
    "                WITH {factor_name}_stats AS (\n",
    "                    SELECT \n",
    "                        security_code,\n",
    "                        SUM(order_volume) AS total_volume,\n",
    "                        SUM(LN(order_price) * order_volume) / SUM(order_volume) AS weighted_log_price\n",
    "                    FROM {factor_name}\n",
    "                    WHERE order_price IS NOT NULL AND order_price > 0  -- 确保只使用有效价格\n",
    "                    GROUP BY security_code\n",
    "                    HAVING COUNT(*) > 1  -- 确保每个证券至少有两条记录\n",
    "                ),\n",
    "\n",
    "                {factor_name}_price_divergence AS (\n",
    "                    SELECT \n",
    "                        o.security_code,\n",
    "                        SQRT(\n",
    "                            SUM(POWER(LN(o.order_price) - s.weighted_log_price, 2) * o.order_volume) / \n",
    "                            ANY_VALUE(s.total_volume)\n",
    "                        ) AS {side}_{interval_name}_{percentile_type}\n",
    "                    FROM {factor_name} o\n",
    "                    JOIN {factor_name}_stats s ON o.security_code = s.security_code\n",
    "                    WHERE o.order_price IS NOT NULL AND o.order_price > 0  -- 确保只使用有效价格\n",
    "                    GROUP BY o.security_code\n",
    "                )\n",
    "\n",
    "                SELECT \n",
    "                    security_code,\n",
    "                    {side}_{interval_name}_{percentile_type}\n",
    "                FROM {factor_name}_price_divergence\n",
    "                \"\"\"\n",
    "                \n",
    "                current_df = conn.execute(factor_query).fetchdf()\n",
    "                \n",
    "                if len(current_df) > 0:\n",
    "                    if result_df is None:\n",
    "                        result_df = current_df\n",
    "                    else:\n",
    "                        result_df = result_df.merge(\n",
    "                            current_df,\n",
    "                            on='security_code',\n",
    "                            how='outer'\n",
    "                        )\n",
    "            except Exception as e:\n",
    "                print(f\"计算因子 {factor_name} 时出错: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"处理日期 {date_str} 时出错: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    # 如果没有结果，返回空DataFrame\n",
    "    if result_df is None or len(result_df) == 0:\n",
    "        columns = ['security_code']\n",
    "        return pd.DataFrame(columns=columns)\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_single_date('2019-03-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_date(trading_date, factor_name):\n",
    "    \n",
    "    \"\"\"处理单个交易日的函数\"\"\"\n",
    "   \n",
    "    date_str = trading_date.strftime('%Y%m%d')\n",
    "    output_dir = f\"./factors/{factor_name}\"\n",
    "    file_path = f\"{output_dir}/{date_str}.parquet\"\n",
    "    \n",
    "    # 如果文件已存在，跳过处理\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"文件已存在，跳过: {date_str}\")\n",
    "        return date_str, True, \"已存在\"\n",
    "    \n",
    "    # 检查原始数据文件是否存在\n",
    "    data_file = f\"/data/cephfs/order/{date_str}.parquet\"\n",
    "    if not os.path.exists(data_file):\n",
    "        print(f\"跳过日期 {date_str}: 原始数据文件不存在\")\n",
    "        return date_str, False, \"数据文件不存在\"\n",
    "    \n",
    "    try:\n",
    "        daily_factor_df = calculate_daily_factor(trading_date)\n",
    "        \n",
    "        daily_factor_df['date'] = date_str\n",
    "\n",
    "        daily_factor_df.to_parquet(file_path, index=False)\n",
    "        print(f\"已生成因子文件: {file_path}\")\n",
    "        return date_str, True, \"成功\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"处理日期 {date_str} 时出错: {error_msg}\")\n",
    "        return date_str, False, error_msg\n",
    "\n",
    "\n",
    "def derive_daily_factor(start_date, end_date, factor_name, num_processes=12):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    trading_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # 创建输出目录\n",
    "    output_dir = f\"./factors/{factor_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 创建进程池\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    \n",
    "    # 创建带有固定参数的处理函数\n",
    "    process_date_with_args = partial(process_single_date, factor_name=factor_name)\n",
    "    \n",
    "    # 提交所有任务到进程池并获取结果\n",
    "    print(f\"开始使用 {num_processes} 个进程并行处理 {len(trading_dates)} 个交易日...\")\n",
    "    results = pool.map(process_date_with_args, trading_dates)\n",
    "    \n",
    "    # 关闭进程池\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # 分析处理结果\n",
    "    processed_dates = [date_str for date_str, success, _ in results if success]\n",
    "    skipped_dates = [date_str for date_str, success, _ in results if not success]\n",
    "    \n",
    "    # 打印处理结果摘要\n",
    "    print(f\"\\n处理完成:\")\n",
    "    print(f\"成功处理 {len(processed_dates)} 个日期\")\n",
    "    print(f\"跳过 {len(skipped_dates)} 个日期\")\n",
    "\n",
    "    return output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已存在，跳过: 20160620文件已存在，跳过: 20160908文件已存在，跳过: 20160819跳过日期 20160710: 原始数据文件不存在文件已存在，跳过: 20160928文件已存在，跳过: 20161018跳过日期 20160730: 原始数据文件不存在文件已存在，跳过: 20161107跳过日期 20161127: 原始数据文件不存在跳过日期 20161217: 原始数据文件不存在文件已存在，跳过: 20170126文件已存在，跳过: 20170106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160909\n",
      "文件已存在，跳过: 20160621文件已存在，跳过: 20161019\n",
      "文件已存在，跳过: 20160711文件已存在，跳过: 20160929跳过日期 20160820: 原始数据文件不存在文件已存在，跳过: 20161108文件已存在，跳过: 20161128跳过日期 20160731: 原始数据文件不存在\n",
      "跳过日期 20161218: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170127: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170107: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20160910: 原始数据文件不存在文件已存在，跳过: 20161020文件已存在，跳过: 20160622\n",
      "文件已存在，跳过: 20160712文件已存在，跳过: 20160930\n",
      "文件已存在，跳过: 20161109跳过日期 20160821: 原始数据文件不存在文件已存在，跳过: 20161129文件已存在，跳过: 20160801文件已存在，跳过: 20161219\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170128: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170108: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160623跳过日期 20160911: 原始数据文件不存在文件已存在，跳过: 20161021文件已存在，跳过: 20160713\n",
      "跳过日期 20161001: 原始数据文件不存在文件已存在，跳过: 20161110\n",
      "文件已存在，跳过: 20160822文件已存在，跳过: 20161130文件已存在，跳过: 20161220\n",
      "文件已存在，跳过: 20160802\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170129: 原始数据文件不存在文件已存在，跳过: 20170109\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160624文件已存在，跳过: 20160912\n",
      "文件已存在，跳过: 20160714跳过日期 20161022: 原始数据文件不存在跳过日期 20161002: 原始数据文件不存在文件已存在，跳过: 20161111\n",
      "\n",
      "文件已存在，跳过: 20160823文件已存在，跳过: 20161201\n",
      "\n",
      "文件已存在，跳过: 20161221文件已存在，跳过: 20160803\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170110\n",
      "跳过日期 20170130: 原始数据文件不存在\n",
      "跳过日期 20160625: 原始数据文件不存在文件已存在，跳过: 20160913\n",
      "\n",
      "文件已存在，跳过: 20160715跳过日期 20161003: 原始数据文件不存在跳过日期 20161023: 原始数据文件不存在跳过日期 20161112: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160824\n",
      "\n",
      "文件已存在，跳过: 20161202\n",
      "文件已存在，跳过: 20160804文件已存在，跳过: 20161222\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170111\n",
      "跳过日期 20170131: 原始数据文件不存在跳过日期 20160626: 原始数据文件不存在文件已存在，跳过: 20160914\n",
      "\n",
      "跳过日期 20160716: 原始数据文件不存在\n",
      "文件已存在，跳过: 20161024跳过日期 20161004: 原始数据文件不存在\n",
      "跳过日期 20161113: 原始数据文件不存在文件已存在，跳过: 20160825\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160805跳过日期 20161203: 原始数据文件不存在\n",
      "文件已存在，跳过: 20161223\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170112\n",
      "跳过日期 20170201: 原始数据文件不存在文件已存在，跳过: 20160627\n",
      "跳过日期 20160915: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20160717: 原始数据文件不存在文件已存在，跳过: 20161025文件已存在，跳过: 20161114\n",
      "跳过日期 20161005: 原始数据文件不存在文件已存在，跳过: 20160826\n",
      "\n",
      "\n",
      "跳过日期 20161204: 原始数据文件不存在\n",
      "跳过日期 20160806: 原始数据文件不存在跳过日期 20161224: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170113\n",
      "\n",
      "文件已存在，跳过: 20160628跳过日期 20170202: 原始数据文件不存在\n",
      "跳过日期 20160916: 原始数据文件不存在文件已存在，跳过: 20160718\n",
      "文件已存在，跳过: 20161026\n",
      "\n",
      "文件已存在，跳过: 20161115跳过日期 20161006: 原始数据文件不存在\n",
      "跳过日期 20160827: 原始数据文件不存在\n",
      "文件已存在，跳过: 20161205\n",
      "\n",
      "跳过日期 20160807: 原始数据文件不存在\n",
      "跳过日期 20161225: 原始数据文件不存在\n",
      "跳过日期 20170114: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160629\n",
      "\n",
      "文件已存在，跳过: 20170203跳过日期 20160917: 原始数据文件不存在文件已存在，跳过: 20160719\n",
      "文件已存在，跳过: 20161027\n",
      "文件已存在，跳过: 20161116\n",
      "\n",
      "跳过日期 20161007: 原始数据文件不存在文件已存在，跳过: 20161206跳过日期 20160828: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160808\n",
      "文件已存在，跳过: 20161226\n",
      "文件已存在，跳过: 20160630跳过日期 20170115: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160720跳过日期 20160918: 原始数据文件不存在\n",
      "跳过日期 20170204: 原始数据文件不存在文件已存在，跳过: 20161028\n",
      "文件已存在，跳过: 20161117\n",
      "\n",
      "文件已存在，跳过: 20160829文件已存在，跳过: 20161207跳过日期 20161008: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20160809\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20161227文件已存在，跳过: 20170116文件已存在，跳过: 20160701\n",
      "\n",
      "文件已存在，跳过: 20160721\n",
      "文件已存在，跳过: 20160919\n",
      "文件已存在，跳过: 20161118跳过日期 20170205: 原始数据文件不存在跳过日期 20161029: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20161208文件已存在，跳过: 20160830\n",
      "\n",
      "跳过日期 20161009: 原始数据文件不存在文件已存在，跳过: 20160810\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170117文件已存在，跳过: 20161228跳过日期 20160702: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20160722文件已存在，跳过: 20160920\n",
      "\n",
      "跳过日期 20161119: 原始数据文件不存在文件已存在，跳过: 20170206\n",
      "\n",
      "跳过日期 20161030: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160831文件已存在，跳过: 20161209\n",
      "\n",
      "文件已存在，跳过: 20161010文件已存在，跳过: 20160811\n",
      "\n",
      "文件已存在，跳过: 20170118文件已存在，跳过: 20161229\n",
      "\n",
      "\n",
      "跳过日期 20160703: 原始数据文件不存在文件已存在，跳过: 20160921\n",
      "跳过日期 20160723: 原始数据文件不存在\n",
      "跳过日期 20161120: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170207\n",
      "文件已存在，跳过: 20161031文件已存在，跳过: 20160901\n",
      "跳过日期 20161210: 原始数据文件不存在\n",
      "文件已存在，跳过: 20161011\n",
      "文件已存在，跳过: 20160812\n",
      "文件已存在，跳过: 20170119\n",
      "文件已存在，跳过: 20161230\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160704文件已存在，跳过: 20160922\n",
      "\n",
      "跳过日期 20160724: 原始数据文件不存在文件已存在，跳过: 20161121\n",
      "\n",
      "文件已存在，跳过: 20170208文件已存在，跳过: 20161101文件已存在，跳过: 20160902\n",
      "\n",
      "文件已存在，跳过: 20161012跳过日期 20161211: 原始数据文件不存在\n",
      "跳过日期 20160813: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170120跳过日期 20161231: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20160705文件已存在，跳过: 20160923\n",
      "\n",
      "文件已存在，跳过: 20160725\n",
      "\n",
      "文件已存在，跳过: 20161122\n",
      "文件已存在，跳过: 20170209文件已存在，跳过: 20161102\n",
      "\n",
      "跳过日期 20160903: 原始数据文件不存在文件已存在，跳过: 20161212\n",
      "文件已存在，跳过: 20161013\n",
      "跳过日期 20160814: 原始数据文件不存在跳过日期 20170121: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170101: 原始数据文件不存在文件已存在，跳过: 20160706跳过日期 20160924: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20160726\n",
      "文件已存在，跳过: 20161123\n",
      "\n",
      "文件已存在，跳过: 20161103文件已存在，跳过: 20170210\n",
      "\n",
      "文件已存在，跳过: 20161213\n",
      "\n",
      "文件已存在，跳过: 20161014跳过日期 20160904: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160815\n",
      "\n",
      "跳过日期 20170122: 原始数据文件不存在\n",
      "跳过日期 20170102: 原始数据文件不存在文件已存在，跳过: 20160707跳过日期 20160925: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160727\n",
      "文件已存在，跳过: 20161124\n",
      "\n",
      "文件已存在，跳过: 20161104跳过日期 20170211: 原始数据文件不存在文件已存在，跳过: 20161214\n",
      "\n",
      "\n",
      "跳过日期 20161015: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20160905文件已存在，跳过: 20160816\n",
      "\n",
      "文件已存在，跳过: 20170123\n",
      "文件已存在，跳过: 20170103文件已存在，跳过: 20160708文件已存在，跳过: 20160926\n",
      "文件已存在，跳过: 20160728文件已存在，跳过: 20161125\n",
      "\n",
      "\n",
      "跳过日期 20161105: 原始数据文件不存在跳过日期 20170212: 原始数据文件不存在文件已存在，跳过: 20161215\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20161016: 原始数据文件不存在\n",
      "文件已存在，跳过: 20160817文件已存在，跳过: 20160906\n",
      "文件已存在，跳过: 20170124\n",
      "文件已存在，跳过: 20160927文件已存在，跳过: 20170104\n",
      "文件已存在，跳过: 20160729\n",
      "跳过日期 20160709: 原始数据文件不存在\n",
      "跳过日期 20161126: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20161106: 原始数据文件不存在文件已存在，跳过: 20170213文件已存在，跳过: 20161216\n",
      "\n",
      "文件已存在，跳过: 20161017\n",
      "\n",
      "文件已存在，跳过: 20160818文件已存在，跳过: 20160907\n",
      "\n",
      "文件已存在，跳过: 20170125\n",
      "\n",
      "文件已存在，跳过: 20170105\n",
      "文件已存在，跳过: 20170215文件已存在，跳过: 20170307\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170214文件已存在，跳过: 20170327跳过日期 20170416: 原始数据文件不存在\n",
      "跳过日期 20170506: 原始数据文件不存在文件已存在，跳过: 20170526文件已存在，跳过: 20170615\n",
      "\n",
      "文件已存在，跳过: 20170705文件已存在，跳过: 20170725\n",
      "文件已存在，跳过: 20170814\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170903: 原始数据文件不存在文件已存在，跳过: 20170216文件已存在，跳过: 20170308\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170417文件已存在，跳过: 20170328跳过日期 20170923: 原始数据文件不存在跳过日期 20170527: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170616跳过日期 20170507: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170726文件已存在，跳过: 20170706文件已存在，跳过: 20170815\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170904\n",
      "\n",
      "文件已存在，跳过: 20170217文件已存在，跳过: 20170309\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170418\n",
      "\n",
      "文件已存在，跳过: 20170329跳过日期 20170528: 原始数据文件不存在跳过日期 20170924: 原始数据文件不存在文件已存在，跳过: 20170508跳过日期 20170617: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170816文件已存在，跳过: 20170727文件已存在，跳过: 20170707\n",
      "\n",
      "文件已存在，跳过: 20170905\n",
      "\n",
      "跳过日期 20170218: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170310\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170419跳过日期 20170529: 原始数据文件不存在文件已存在，跳过: 20170330\n",
      "文件已存在，跳过: 20170925文件已存在，跳过: 20170509\n",
      "跳过日期 20170618: 原始数据文件不存在文件已存在，跳过: 20170817文件已存在，跳过: 20170728跳过日期 20170708: 原始数据文件不存在文件已存在，跳过: 20170906\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170219: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170311: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170420跳过日期 20170530: 原始数据文件不存在文件已存在，跳过: 20170926\n",
      "文件已存在，跳过: 20170331文件已存在，跳过: 20170510文件已存在，跳过: 20170619\n",
      "文件已存在，跳过: 20170818文件已存在，跳过: 20170907跳过日期 20170729: 原始数据文件不存在跳过日期 20170709: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170220\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170312: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170531文件已存在，跳过: 20170421\n",
      "文件已存在，跳过: 20170927文件已存在，跳过: 20170620文件已存在，跳过: 20170511跳过日期 20170401: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170908跳过日期 20170819: 原始数据文件不存在文件已存在，跳过: 20170710跳过日期 20170730: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170221\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170313\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170601\n",
      "跳过日期 20170422: 原始数据文件不存在文件已存在，跳过: 20170621文件已存在，跳过: 20170512文件已存在，跳过: 20170928跳过日期 20170909: 原始数据文件不存在跳过日期 20170402: 原始数据文件不存在\n",
      "跳过日期 20170820: 原始数据文件不存在文件已存在，跳过: 20170711文件已存在，跳过: 20170731文件已存在，跳过: 20170222\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170314\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170602文件已存在，跳过: 20170622跳过日期 20170423: 原始数据文件不存在跳过日期 20170513: 原始数据文件不存在跳过日期 20170910: 原始数据文件不存在文件已存在，跳过: 20170929\n",
      "文件已存在，跳过: 20170712文件已存在，跳过: 20170821跳过日期 20170403: 原始数据文件不存在文件已存在，跳过: 20170801\n",
      "文件已存在，跳过: 20170223\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170424跳过日期 20170603: 原始数据文件不存在文件已存在，跳过: 20170623文件已存在，跳过: 20170911跳过日期 20170514: 原始数据文件不存在跳过日期 20170930: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170713文件已存在，跳过: 20170802文件已存在，跳过: 20170822\n",
      "文件已存在，跳过: 20170224跳过日期 20170404: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170604: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170425文件已存在，跳过: 20170912文件已存在，跳过: 20170515跳过日期 20170624: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170714文件已存在，跳过: 20170823文件已存在，跳过: 20170803跳过日期 20171001: 原始数据文件不存在跳过日期 20170225: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170405\n",
      "\n",
      "文件已存在，跳过: 20170317\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170605\n",
      "文件已存在，跳过: 20170426文件已存在，跳过: 20170516跳过日期 20170625: 原始数据文件不存在文件已存在，跳过: 20170913\n",
      "\n",
      "文件已存在，跳过: 20170824文件已存在，跳过: 20170804跳过日期 20170715: 原始数据文件不存在\n",
      "跳过日期 20171002: 原始数据文件不存在跳过日期 20170226: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170406\n",
      "\n",
      "\n",
      "跳过日期 20170318: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170606\n",
      "\n",
      "文件已存在，跳过: 20170427文件已存在，跳过: 20170914\n",
      "文件已存在，跳过: 20170517文件已存在，跳过: 20170626\n",
      "文件已存在，跳过: 20170825\n",
      "跳过日期 20170805: 原始数据文件不存在跳过日期 20170716: 原始数据文件不存在文件已存在，跳过: 20170227\n",
      "跳过日期 20171003: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170407\n",
      "\n",
      "\n",
      "跳过日期 20170319: 原始数据文件不存在文件已存在，跳过: 20170607\n",
      "\n",
      "文件已存在，跳过: 20170428\n",
      "文件已存在，跳过: 20170915\n",
      "\n",
      "文件已存在，跳过: 20170627跳过日期 20170826: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170518\n",
      "文件已存在，跳过: 20170717跳过日期 20170806: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170228跳过日期 20171004: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170408: 原始数据文件不存在文件已存在，跳过: 20170320\n",
      "文件已存在，跳过: 20170608\n",
      "\n",
      "跳过日期 20170429: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170916: 原始数据文件不存在文件已存在，跳过: 20170628\n",
      "跳过日期 20170827: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170519文件已存在，跳过: 20170718文件已存在，跳过: 20170807\n",
      "文件已存在，跳过: 20170301\n",
      "跳过日期 20171005: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170409: 原始数据文件不存在文件已存在，跳过: 20170321文件已存在，跳过: 20170609\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20170430: 原始数据文件不存在文件已存在，跳过: 20170629跳过日期 20170917: 原始数据文件不存在文件已存在，跳过: 20170828\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170719文件已存在，跳过: 20170808文件已存在，跳过: 20170302跳过日期 20170520: 原始数据文件不存在跳过日期 20171006: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20170410文件已存在，跳过: 20170322\n",
      "\n",
      "跳过日期 20170610: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20170501: 原始数据文件不存在文件已存在，跳过: 20170630文件已存在，跳过: 20170918文件已存在，跳过: 20170829\n",
      "\n",
      "文件已存在，跳过: 20170720文件已存在，跳过: 20170303\n",
      "文件已存在，跳过: 20170809跳过日期 20171007: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20170521: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170411文件已存在，跳过: 20170323\n",
      "\n",
      "\n",
      "跳过日期 20170611: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170502跳过日期 20170701: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170830文件已存在，跳过: 20170919\n",
      "文件已存在，跳过: 20170721\n",
      "跳过日期 20170304: 原始数据文件不存在文件已存在，跳过: 20170810\n",
      "\n",
      "跳过日期 20171008: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170522\n",
      "\n",
      "文件已存在，跳过: 20170324\n",
      "文件已存在，跳过: 20170412\n",
      "\n",
      "文件已存在，跳过: 20170612文件已存在，跳过: 20170503\n",
      "跳过日期 20170702: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170920文件已存在，跳过: 20170831\n",
      "跳过日期 20170722: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170811跳过日期 20170305: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20171009\n",
      "文件已存在，跳过: 20170523\n",
      "\n",
      "\n",
      "跳过日期 20170325: 原始数据文件不存在文件已存在，跳过: 20170413\n",
      "\n",
      "文件已存在，跳过: 20170613文件已存在，跳过: 20170504\n",
      "文件已存在，跳过: 20170703\n",
      "文件已存在，跳过: 20170921\n",
      "文件已存在，跳过: 20170901跳过日期 20170723: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170306\n",
      "跳过日期 20170812: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171010\n",
      "\n",
      "文件已存在，跳过: 20170524\n",
      "\n",
      "跳过日期 20170326: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170414\n",
      "\n",
      "文件已存在，跳过: 20170505文件已存在，跳过: 20170614\n",
      "文件已存在，跳过: 20170922文件已存在，跳过: 20170704跳过日期 20170902: 原始数据文件不存在\n",
      "文件已存在，跳过: 20170724\n",
      "文件已存在，跳过: 20171013\n",
      "\n",
      "文件已存在，跳过: 20171011跳过日期 20170813: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20170525\n",
      "\n",
      "文件已存在，跳过: 20171102\n",
      "\n",
      "跳过日期 20170415: 原始数据文件不存在文件已存在，跳过: 20171122\n",
      "文件已存在，跳过: 20171212\n",
      "跳过日期 20180101: 原始数据文件不存在跳过日期 20180121: 原始数据文件不存在\n",
      "跳过日期 20180210: 原始数据文件不存在文件已存在，跳过: 20180302跳过日期 20171014: 原始数据文件不存在文件已存在，跳过: 20171012\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180322\n",
      "\n",
      "文件已存在，跳过: 20171103文件已存在，跳过: 20180411\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171123文件已存在，跳过: 20171213文件已存在，跳过: 20180102跳过日期 20180501: 原始数据文件不存在文件已存在，跳过: 20180122\n",
      "跳过日期 20180211: 原始数据文件不存在\n",
      "跳过日期 20180303: 原始数据文件不存在跳过日期 20171015: 原始数据文件不存在文件已存在，跳过: 20180323\n",
      "文件已存在，跳过: 20180521\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20171104: 原始数据文件不存在文件已存在，跳过: 20180412\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171124\n",
      "\n",
      "文件已存在，跳过: 20171214文件已存在，跳过: 20180123文件已存在，跳过: 20180103文件已存在，跳过: 20180502\n",
      "\n",
      "文件已存在，跳过: 20180212跳过日期 20180304: 原始数据文件不存在文件已存在，跳过: 20171016\n",
      "跳过日期 20180324: 原始数据文件不存在文件已存在，跳过: 20180522\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180413\n",
      "\n",
      "跳过日期 20171105: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20171125: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171215文件已存在，跳过: 20180104文件已存在，跳过: 20180124\n",
      "文件已存在，跳过: 20180503文件已存在，跳过: 20180305文件已存在，跳过: 20180213\n",
      "文件已存在，跳过: 20171017\n",
      "跳过日期 20180325: 原始数据文件不存在文件已存在，跳过: 20180523\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20180414: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20171106\n",
      "\n",
      "跳过日期 20171126: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180125文件已存在，跳过: 20180105跳过日期 20171216: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180504文件已存在，跳过: 20180306文件已存在，跳过: 20180214\n",
      "文件已存在，跳过: 20171018文件已存在，跳过: 20180326\n",
      "文件已存在，跳过: 20180524\n",
      "\n",
      "\n",
      "跳过日期 20180415: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171107\n",
      "\n",
      "文件已存在，跳过: 20171127\n",
      "文件已存在，跳过: 20180126跳过日期 20180106: 原始数据文件不存在跳过日期 20171217: 原始数据文件不存在\n",
      "跳过日期 20180215: 原始数据文件不存在文件已存在，跳过: 20180307\n",
      "跳过日期 20180505: 原始数据文件不存在文件已存在，跳过: 20171019文件已存在，跳过: 20180327\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180525文件已存在，跳过: 20180416\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171108\n",
      "文件已存在，跳过: 20171128\n",
      "\n",
      "跳过日期 20180127: 原始数据文件不存在跳过日期 20180107: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20171218跳过日期 20180216: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180308文件已存在，跳过: 20171020\n",
      "文件已存在，跳过: 20180328跳过日期 20180506: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180417跳过日期 20180526: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171109\n",
      "\n",
      "文件已存在，跳过: 20171129\n",
      "文件已存在，跳过: 20180108\n",
      "跳过日期 20180128: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171219\n",
      "文件已存在，跳过: 20180309跳过日期 20180217: 原始数据文件不存在跳过日期 20171021: 原始数据文件不存在文件已存在，跳过: 20180329\n",
      "\n",
      "文件已存在，跳过: 20180418\n",
      "文件已存在，跳过: 20180507跳过日期 20180527: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20171110\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171130文件已存在，跳过: 20180109\n",
      "文件已存在，跳过: 20180129\n",
      "\n",
      "文件已存在，跳过: 20171220跳过日期 20180310: 原始数据文件不存在\n",
      "跳过日期 20180218: 原始数据文件不存在文件已存在，跳过: 20180330跳过日期 20171022: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180419\n",
      "文件已存在，跳过: 20180528文件已存在，跳过: 20180508\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20171111: 原始数据文件不存在文件已存在，跳过: 20180110文件已存在，跳过: 20171201\n",
      "文件已存在，跳过: 20180130\n",
      "\n",
      "文件已存在，跳过: 20171221跳过日期 20180311: 原始数据文件不存在跳过日期 20180219: 原始数据文件不存在\n",
      "跳过日期 20180331: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171023\n",
      "文件已存在，跳过: 20180420\n",
      "文件已存在，跳过: 20180509文件已存在，跳过: 20180529\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20171112: 原始数据文件不存在文件已存在，跳过: 20180111\n",
      "\n",
      "跳过日期 20171202: 原始数据文件不存在文件已存在，跳过: 20180131\n",
      "文件已存在，跳过: 20171222\n",
      "文件已存在，跳过: 20180312\n",
      "跳过日期 20180220: 原始数据文件不存在跳过日期 20180401: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171024\n",
      "\n",
      "跳过日期 20180421: 原始数据文件不存在文件已存在，跳过: 20180510文件已存在，跳过: 20180530\n",
      "\n",
      "文件已存在，跳过: 20171113\n",
      "\n",
      "文件已存在，跳过: 20180112\n",
      "文件已存在，跳过: 20180201跳过日期 20171203: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180313\n",
      "跳过日期 20171223: 原始数据文件不存在跳过日期 20180221: 原始数据文件不存在文件已存在，跳过: 20180402\n",
      "文件已存在，跳过: 20171025\n",
      "\n",
      "文件已存在，跳过: 20180511跳过日期 20180422: 原始数据文件不存在文件已存在，跳过: 20180531\n",
      "文件已存在，跳过: 20171114\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180202跳过日期 20180113: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171204\n",
      "\n",
      "文件已存在，跳过: 20180314文件已存在，跳过: 20180222\n",
      "文件已存在，跳过: 20180403文件已存在，跳过: 20171026跳过日期 20171224: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180423\n",
      "文件已存在，跳过: 20180601\n",
      "跳过日期 20180512: 原始数据文件不存在文件已存在，跳过: 20171115\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171205\n",
      "跳过日期 20180203: 原始数据文件不存在跳过日期 20180114: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180315\n",
      "\n",
      "文件已存在，跳过: 20180223文件已存在，跳过: 20180404文件已存在，跳过: 20171027文件已存在，跳过: 20171225\n",
      "文件已存在，跳过: 20180424\n",
      "\n",
      "\n",
      "跳过日期 20180602: 原始数据文件不存在文件已存在，跳过: 20171116\n",
      "\n",
      "\n",
      "跳过日期 20180513: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171206\n",
      "文件已存在，跳过: 20180115跳过日期 20180204: 原始数据文件不存在文件已存在，跳过: 20180316\n",
      "\n",
      "跳过日期 20180224: 原始数据文件不存在跳过日期 20180405: 原始数据文件不存在跳过日期 20171028: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171226\n",
      "文件已存在，跳过: 20180425\n",
      "\n",
      "文件已存在，跳过: 20171117跳过日期 20180603: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180514文件已存在，跳过: 20171207\n",
      "\n",
      "文件已存在，跳过: 20180116文件已存在，跳过: 20180205\n",
      "\n",
      "跳过日期 20180317: 原始数据文件不存在跳过日期 20180225: 原始数据文件不存在跳过日期 20180406: 原始数据文件不存在\n",
      "跳过日期 20171029: 原始数据文件不存在\n",
      "文件已存在，跳过: 20171227文件已存在，跳过: 20180426\n",
      "\n",
      "跳过日期 20171118: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180604\n",
      "文件已存在，跳过: 20180515\n",
      "文件已存在，跳过: 20171208\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180117文件已存在，跳过: 20180206\n",
      "跳过日期 20180318: 原始数据文件不存在文件已存在，跳过: 20180226\n",
      "跳过日期 20180407: 原始数据文件不存在文件已存在，跳过: 20171030\n",
      "文件已存在，跳过: 20171228文件已存在，跳过: 20180427\n",
      "\n",
      "文件已存在，跳过: 20180605跳过日期 20171119: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180516\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20171209: 原始数据文件不存在文件已存在，跳过: 20180207文件已存在，跳过: 20180118\n",
      "\n",
      "文件已存在，跳过: 20180319\n",
      "文件已存在，跳过: 20180227文件已存在，跳过: 20171031文件已存在，跳过: 20171229跳过日期 20180408: 原始数据文件不存在跳过日期 20180428: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180606文件已存在，跳过: 20171120\n",
      "文件已存在，跳过: 20180517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180208跳过日期 20171210: 原始数据文件不存在文件已存在，跳过: 20180119\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20171101文件已存在，跳过: 20180320文件已存在，跳过: 20180228文件已存在，跳过: 20180409跳过日期 20171230: 原始数据文件不存在跳过日期 20180429: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180607文件已存在，跳过: 20180518\n",
      "文件已存在，跳过: 20171121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180209文件已存在，跳过: 20171211\n",
      "\n",
      "跳过日期 20180120: 原始数据文件不存在文件已存在，跳过: 20180321文件已存在，跳过: 20180301\n",
      "文件已存在，跳过: 20180410跳过日期 20180610: 原始数据文件不存在跳过日期 20171231: 原始数据文件不存在\n",
      "跳过日期 20180430: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180608\n",
      "\n",
      "跳过日期 20180519: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180630: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180720\n",
      "文件已存在，跳过: 20180809文件已存在，跳过: 20180829文件已存在，跳过: 20180918\n",
      "文件已存在，跳过: 20181008\n",
      "文件已存在，跳过: 20180611跳过日期 20181028: 原始数据文件不存在文件已存在，跳过: 20181207跳过日期 20181117: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20180609: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20180520: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180701: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180721: 原始数据文件不存在文件已存在，跳过: 20180810文件已存在，跳过: 20180830\n",
      "文件已存在，跳过: 20180919文件已存在，跳过: 20181009文件已存在，跳过: 20180612文件已存在，跳过: 20181029\n",
      "跳过日期 20181208: 原始数据文件不存在跳过日期 20181118: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181227\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190116\n",
      "\n",
      "文件已存在，跳过: 20180702\n",
      "\n",
      "文件已存在，跳过: 20180831\n",
      "跳过日期 20180722: 原始数据文件不存在跳过日期 20180811: 原始数据文件不存在文件已存在，跳过: 20181010文件已存在，跳过: 20180920\n",
      "文件已存在，跳过: 20180613文件已存在，跳过: 20181030\n",
      "文件已存在，跳过: 20181119跳过日期 20181209: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181228\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190117\n",
      "文件已存在，跳过: 20180703\n",
      "\n",
      "\n",
      "跳过日期 20180901: 原始数据文件不存在文件已存在，跳过: 20180723跳过日期 20180812: 原始数据文件不存在文件已存在，跳过: 20181011文件已存在，跳过: 20180921文件已存在，跳过: 20180614\n",
      "文件已存在，跳过: 20181031\n",
      "文件已存在，跳过: 20181210文件已存在，跳过: 20181120\n",
      "\n",
      "跳过日期 20181229: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190118\n",
      "文件已存在，跳过: 20180704\n",
      "\n",
      "文件已存在，跳过: 20180724跳过日期 20180902: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180813文件已存在，跳过: 20181012文件已存在，跳过: 20180615\n",
      "跳过日期 20180922: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181101文件已存在，跳过: 20181211文件已存在，跳过: 20181121\n",
      "\n",
      "\n",
      "跳过日期 20181230: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20190119: 原始数据文件不存在文件已存在，跳过: 20180705\n",
      "文件已存在，跳过: 20180725\n",
      "\n",
      "文件已存在，跳过: 20180903\n",
      "文件已存在，跳过: 20180814跳过日期 20180616: 原始数据文件不存在跳过日期 20181013: 原始数据文件不存在\n",
      "跳过日期 20180923: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181102文件已存在，跳过: 20181212\n",
      "文件已存在，跳过: 20181122\n",
      "\n",
      "\n",
      "跳过日期 20181231: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180706跳过日期 20190120: 原始数据文件不存在文件已存在，跳过: 20180726\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180815\n",
      "文件已存在，跳过: 20180904跳过日期 20180617: 原始数据文件不存在跳过日期 20181014: 原始数据文件不存在跳过日期 20180924: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20181213文件已存在，跳过: 20181123跳过日期 20181103: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20190101: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20180707: 原始数据文件不存在文件已存在，跳过: 20180727\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180816文件已存在，跳过: 20180905跳过日期 20180618: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181015文件已存在，跳过: 20180925\n",
      "\n",
      "文件已存在，跳过: 20181214\n",
      "跳过日期 20181124: 原始数据文件不存在跳过日期 20181104: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20190102\n",
      "\n",
      "跳过日期 20180708: 原始数据文件不存在\n",
      "跳过日期 20180728: 原始数据文件不存在文件已存在，跳过: 20180817\n",
      "\n",
      "文件已存在，跳过: 20180619文件已存在，跳过: 20180906\n",
      "文件已存在，跳过: 20180926文件已存在，跳过: 20181016\n",
      "\n",
      "跳过日期 20181215: 原始数据文件不存在\n",
      "跳过日期 20181125: 原始数据文件不存在文件已存在，跳过: 20181105\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190103\n",
      "文件已存在，跳过: 20180709跳过日期 20180729: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180818: 原始数据文件不存在文件已存在，跳过: 20180620文件已存在，跳过: 20180907文件已存在，跳过: 20180927\n",
      "文件已存在，跳过: 20181017\n",
      "\n",
      "跳过日期 20181216: 原始数据文件不存在文件已存在，跳过: 20181126文件已存在，跳过: 20181106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190104文件已存在，跳过: 20180710文件已存在，跳过: 20180730\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180621跳过日期 20180819: 原始数据文件不存在跳过日期 20180908: 原始数据文件不存在文件已存在，跳过: 20180928文件已存在，跳过: 20181018\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20181217文件已存在，跳过: 20181127文件已存在，跳过: 20181107\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180711文件已存在，跳过: 20180731跳过日期 20190105: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180622\n",
      "文件已存在，跳过: 20180820跳过日期 20180909: 原始数据文件不存在文件已存在，跳过: 20181019跳过日期 20180929: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20181218\n",
      "文件已存在，跳过: 20181128\n",
      "文件已存在，跳过: 20181108\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180712文件已存在，跳过: 20180801\n",
      "开始使用 12 个进程并行处理 945 个交易日...\n",
      "跳过日期 20190106: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20180623: 原始数据文件不存在文件已存在，跳过: 20180821文件已存在，跳过: 20180910跳过日期 20180930: 原始数据文件不存在\n",
      "\n",
      "跳过日期 20181020: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181129文件已存在，跳过: 20181219文件已存在，跳过: 20181109\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180713文件已存在，跳过: 20180802文件已存在，跳过: 20190107\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180822文件已存在，跳过: 20180911跳过日期 20180624: 原始数据文件不存在\n",
      "跳过日期 20181001: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20181220跳过日期 20181021: 原始数据文件不存在文件已存在，跳过: 20181130跳过日期 20181110: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180714: 原始数据文件不存在文件已存在，跳过: 20180803\n",
      "文件已存在，跳过: 20190108\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180912文件已存在，跳过: 20180625文件已存在，跳过: 20180823\n",
      "\n",
      "\n",
      "跳过日期 20181002: 原始数据文件不存在文件已存在，跳过: 20181221文件已存在，跳过: 20181022跳过日期 20181111: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20181201: 原始数据文件不存在文件已存在，跳过: 20190109跳过日期 20180715: 原始数据文件不存在跳过日期 20180804: 原始数据文件不存在\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180913文件已存在，跳过: 20180824文件已存在，跳过: 20180626\n",
      "\n",
      "\n",
      "跳过日期 20181003: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181023文件已存在，跳过: 20181112跳过日期 20181222: 原始数据文件不存在\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190110文件已存在，跳过: 20180716跳过日期 20181202: 原始数据文件不存在\n",
      "\n",
      "\n",
      "跳过日期 20180805: 原始数据文件不存在跳过日期 20180825: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180914文件已存在，跳过: 20180627\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20181024跳过日期 20181004: 原始数据文件不存在文件已存在，跳过: 20181113\n",
      "\n",
      "跳过日期 20181223: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20190111文件已存在，跳过: 20180717文件已存在，跳过: 20181203\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20180806跳过日期 20180915: 原始数据文件不存在跳过日期 20180826: 原始数据文件不存在\n",
      "文件已存在，跳过: 20180628\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20181025文件已存在，跳过: 20181114\n",
      "\n",
      "跳过日期 20181005: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181224\n",
      "文件已存在，跳过: 20181204文件已存在，跳过: 20180718跳过日期 20190112: 原始数据文件不存在文件已存在，跳过: 20180807\n",
      "\n",
      "跳过日期 20180916: 原始数据文件不存在\n",
      "\n",
      "文件已存在，跳过: 20180827文件已存在，跳过: 20180629\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20181026\n",
      "\n",
      "文件已存在，跳过: 20181115跳过日期 20181006: 原始数据文件不存在\n",
      "文件已存在，跳过: 20181225\n",
      "文件已存在，跳过: 20180719文件已存在，跳过: 20181205\n",
      "跳过日期 20190113: 原始数据文件不存在文件已存在，跳过: 20180808文件已存在，跳过: 20180917\n",
      "\n",
      "文件已存在，跳过: 20180828\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "跳过日期 20181027: 原始数据文件不存在文件已存在，跳过: 20181116\n",
      "文件已存在，跳过: 20181226\n",
      "跳过日期 20181007: 原始数据文件不存在文件已存在，跳过: 20181206文件已存在，跳过: 20190114\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文件已存在，跳过: 20190115\n",
      "\n",
      "处理完成:\n",
      "成功处理 633 个日期\n",
      "跳过 312 个日期\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_date = '2016-06-20'\n",
    "    end_date = '2019-01-20'\n",
    "    factor_name = '3_97_percent_price_divergence'\n",
    "    factor_dir = derive_daily_factor (start_date, end_date, factor_name)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "def standardize_parquet_files(factor_dir):\n",
    "    \"\"\"\n",
    "    读取目录中的所有Parquet文件，确保它们具有相同的列结构，然后重新保存。\n",
    "    \n",
    "    参数:\n",
    "    factor_dir (str): 包含Parquet文件的目录路径\n",
    "    \n",
    "    返回:\n",
    "    int: 处理的文件数量\n",
    "    \"\"\"\n",
    "    # 获取目录中的所有parquet文件\n",
    "    parquet_files = glob.glob(os.path.join(factor_dir, \"*.parquet\"))\n",
    "    if not parquet_files:\n",
    "        print(f\"在目录 {factor_dir} 中未找到Parquet文件\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"在目录 {factor_dir} 中找到 {len(parquet_files)} 个Parquet文件\")\n",
    "\n",
    "    all_columns = set(['date','security_code', 'bid_pre_open_915_920_p01_p99',\n",
    "       'bid_pre_open_915_920_p05_p95', 'ask_pre_open_915_920_p01_p99',\n",
    "       'ask_pre_open_915_920_p05_p95', 'bid_pre_open_920_925_p01_p99',\n",
    "       'bid_pre_open_920_925_p05_p95', 'ask_pre_open_920_925_p01_p99',\n",
    "       'ask_pre_open_920_925_p05_p95', 'bid_early_930_1000_p01_p99',\n",
    "       'bid_early_930_1000_p05_p95', 'ask_early_930_1000_p01_p99',\n",
    "       'ask_early_930_1000_p05_p95', 'bid_main_1000_1430_p01_p99',\n",
    "       'bid_main_1000_1430_p05_p95', 'ask_main_1000_1430_p01_p99',\n",
    "       'ask_main_1000_1430_p05_p95', 'bid_late_1430_1457_p01_p99',\n",
    "       'bid_late_1430_1457_p05_p95', 'ask_late_1430_1457_p01_p99',\n",
    "       'ask_late_1430_1457_p05_p95', 'bid_close_1457_1500_p01_p99',\n",
    "       'bid_close_1457_1500_p05_p95', 'ask_close_1457_1500_p01_p99',\n",
    "       'ask_close_1457_1500_p05_p95', 'bid_continue_930_1457_p01_p99',\n",
    "       'bid_continue_930_1457_p05_p95', 'ask_continue_930_1457_p01_p99',\n",
    "       'ask_continue_930_1457_p05_p95'])\n",
    "    \n",
    "    # # 收集所有文件中的所有列名\n",
    "    # all_columns = set(['security_code', 'date', \n",
    "    #     'pre_open_915_920', \n",
    "    #     'pre_open_920_925', \n",
    "    #     'early_930_1000', \n",
    "    #     'main_1000_1430', \n",
    "    #     'late_1430_1457', \n",
    "    #     'close_1457_1500',\n",
    "    #     'continue_930_1457'])  # 这些列必须存在\n",
    "    \n",
    "    # # 定义所有可能的因子列名\n",
    "    # time_intervals = [\n",
    "    #     'pre_open_915_920', \n",
    "    #     'pre_open_920_925', \n",
    "    #     'early_930_1000', \n",
    "    #     'main_1000_1430', \n",
    "    #     'late_1430_1457', \n",
    "    #     'close_1457_1500',\n",
    "    #     'continue_930_1457'\n",
    "    # ]\n",
    "    \n",
    "    # for interval in time_intervals:\n",
    "    #     all_columns.add(f\"bid_{interval}\")\n",
    "    \n",
    "    # 处理每个文件\n",
    "    for i, file_path in enumerate(parquet_files):\n",
    "        try:\n",
    "            # 读取Parquet文件\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # 添加缺失的列\n",
    "            missing_columns = all_columns - set(df.columns)\n",
    "            for col in missing_columns:\n",
    "                df[col] = np.nan\n",
    "            \n",
    "            # 如果缺少factor_name列，添加它\n",
    "            if 'factor_name' not in df.columns:\n",
    "                df['factor_name'] = \"3_97_percent_price_divergence\"\n",
    "            \n",
    "            # 重新保存文件\n",
    "            df.to_parquet(file_path, index=False)\n",
    "            \n",
    "            if (i+1) % 10 == 0 or i+1 == len(parquet_files):\n",
    "                print(f\"已处理 {i+1}/{len(parquet_files)} 个文件\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {file_path} 时出错: {str(e)}\")\n",
    "    \n",
    "    print(\"所有文件处理完成\")\n",
    "    return len(parquet_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_pivot_factor(all_factor_data, factor_name):\n",
    "    \"\"\"\n",
    "    筛选特定因子列且该列不为NaN的数据，并进行透视\n",
    "    \n",
    "    参数:\n",
    "    all_factor_data: 原始数据DataFrame\n",
    "    factor_name: 要筛选的因子列名称，例如'bid_pre_open_915_920_p01_p99'\n",
    "    \n",
    "    返回:\n",
    "    透视后的DataFrame，索引为date，列为security_code\n",
    "    \"\"\"\n",
    "    # 步骤1: 筛选必要的列\n",
    "    filtered_data = all_factor_data[['date', 'security_code', factor_name]]\n",
    "    \n",
    "    # 步骤2: 去除因子列为NaN的行\n",
    "    filtered_data = filtered_data.dropna(subset=[factor_name])\n",
    "    \n",
    "    # 步骤3: 检查是否存在重复的(date, security_code)组合\n",
    "    duplicates = filtered_data.duplicated(subset=['date', 'security_code'], keep=False)\n",
    "    if duplicates.any():\n",
    "        print(f\"警告: 发现{duplicates.sum()}条重复记录，将保留第一条\")\n",
    "        # 如果有重复，保留第一条\n",
    "        filtered_data = filtered_data.drop_duplicates(subset=['date', 'security_code'], keep='first')\n",
    "\n",
    "    output_path = f\"/data/home/lexuanchen/Factors/Order/Signal/1_100_Percent_Raw_Price_Divergence\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file_path = f\"{output_path}/Raw_{factor_name}.csv\"\n",
    "    filtered_data.to_csv(output_file_path)\n",
    "    print(f\"已成功保存因子原文件：{factor_name}\")\n",
    "    \n",
    "    # 步骤4: 透视表，将security_code作为列，date作为索引\n",
    "    pivot_data = filtered_data.pivot(index='date', columns='security_code', values=factor_name)\n",
    "    \n",
    "    return pivot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_20d_avg(factor_names, factor_dir, start_date=None, end_date=None, min_window=5):\n",
    "    \n",
    "    print(factor_names)\n",
    "    \n",
    "    if not isinstance(factor_names, list):\n",
    "        factor_names = [factor_names]\n",
    "    \n",
    "    parquet_pattern = os.path.join(factor_dir, \"*.parquet\")\n",
    "    parquet_files = glob.glob(parquet_pattern)\n",
    "    print(f\"在目录 {factor_dir} 中找到 {len(parquet_files)} 个Parquet文件\")\n",
    "    \n",
    "\n",
    "    conn = duckdb.connect(database=':memory:')\n",
    "    all_factor_data = conn.execute(f\"\"\"\n",
    "        SELECT * FROM read_parquet('{parquet_pattern}')\n",
    "    \"\"\").fetchdf()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "\n",
    "    missing_factors = [f for f in factor_names if f not in all_factor_data.columns]\n",
    "    if missing_factors:\n",
    "        raise ValueError(f\"在Parquet文件中未找到以下因子列: {', '.join(missing_factors)}\")\n",
    "    \n",
    "    all_factor_data['date'] = pd.to_datetime(all_factor_data['date'])\n",
    "\n",
    "    all_factor_data = all_factor_data.sort_values(['date', 'security_code'])\n",
    "    \n",
    "    # 筛选日期范围\n",
    "    if start_date:\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        all_factor_data = all_factor_data[all_factor_data['date'] >= start_date]\n",
    "    if end_date:\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "        all_factor_data = all_factor_data[all_factor_data['date'] <= end_date]\n",
    "\n",
    "    # 获取所有个股代码\n",
    "    all_securities = all_factor_data['security_code'].unique()\n",
    "\n",
    "    result_df = all_factor_data[['date', 'security_code']].copy()\n",
    "\n",
    "    # 为每个因子计算滚动平均\n",
    "    for factor_name in factor_names:\n",
    "        print(f\"\\n处理因子: {factor_name}\")\n",
    "        \n",
    "        #转置成宽表\n",
    "        pivot_data = filter_and_pivot_factor(all_factor_data,factor_name)\n",
    "\n",
    "        # 对宽表直接应用rolling\n",
    "        rolling_avg = pivot_data.rolling(window=20, min_periods=min_window).mean()\n",
    "\n",
    "        # 将结果转换回长格式\n",
    "        factor_df = rolling_avg.stack().reset_index()\n",
    "        factor_df.columns = ['date', 'security_code', factor_name]\n",
    "        factor_df[factor_name] = - factor_df[factor_name]\n",
    "\n",
    "        # 计算每日因子覆盖率\n",
    "        # 计算每个日期非NaN的因子值数量\n",
    "        non_nan_counts = factor_df.dropna(subset=[factor_name]).groupby('date').size()\n",
    "\n",
    "        # 计算覆盖率\n",
    "        coverage = non_nan_counts / len(all_securities)\n",
    "        print(f\"\\n{factor_name}因子覆盖率统计: 平均={coverage.mean():.2f}, 最小={coverage.min():.2f}\")\n",
    "\n",
    "        result_df = pd.merge(\n",
    "            result_df, \n",
    "            factor_df,\n",
    "            on=['date', 'security_code'],\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bid_pre_open_915_920_p03_p97', 'bid_pre_open_920_925_p03_p97', 'bid_early_930_1000_p03_p97', 'bid_main_1000_1430_p03_p97', 'bid_late_1430_1457_p03_p97', 'bid_close_1457_1500_p03_p97', 'bid_continue_930_1457_p03_p97']\n",
      "在目录 ./factors/3_97_percent_price_divergence 中找到 2164 个Parquet文件\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be937404ce6145d48f19bc20473c01e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理因子: bid_pre_open_915_920_p03_p97\n",
      "已成功保存因子原文件：bid_pre_open_915_920_p03_p97\n",
      "\n",
      "bid_pre_open_915_920_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_pre_open_920_925_p03_p97\n",
      "已成功保存因子原文件：bid_pre_open_920_925_p03_p97\n",
      "\n",
      "bid_pre_open_920_925_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_early_930_1000_p03_p97\n",
      "已成功保存因子原文件：bid_early_930_1000_p03_p97\n",
      "\n",
      "bid_early_930_1000_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_main_1000_1430_p03_p97\n",
      "已成功保存因子原文件：bid_main_1000_1430_p03_p97\n",
      "\n",
      "bid_main_1000_1430_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_late_1430_1457_p03_p97\n",
      "已成功保存因子原文件：bid_late_1430_1457_p03_p97\n",
      "\n",
      "bid_late_1430_1457_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_close_1457_1500_p03_p97\n",
      "已成功保存因子原文件：bid_close_1457_1500_p03_p97\n",
      "\n",
      "bid_close_1457_1500_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "\n",
      "处理因子: bid_continue_930_1457_p03_p97\n",
      "已成功保存因子原文件：bid_continue_930_1457_p03_p97\n",
      "\n",
      "bid_continue_930_1457_p03_p97因子覆盖率统计: 平均=0.77, 最小=0.47\n",
      "bid_p03_p97 因子共计 8852399 条记录\n",
      "\n",
      "数据预览:\n",
      "        date security_code  bid_pre_open_915_920_p03_p97  \\\n",
      "0 2016-06-20        000001                           NaN   \n",
      "1 2016-06-20        000005                           NaN   \n",
      "2 2016-06-20        000006                           NaN   \n",
      "3 2016-06-20        000008                           NaN   \n",
      "4 2016-06-20        000009                           NaN   \n",
      "\n",
      "   bid_pre_open_920_925_p03_p97  bid_early_930_1000_p03_p97  \\\n",
      "0                           NaN                         NaN   \n",
      "1                           NaN                         NaN   \n",
      "2                           NaN                         NaN   \n",
      "3                           NaN                         NaN   \n",
      "4                           NaN                         NaN   \n",
      "\n",
      "   bid_main_1000_1430_p03_p97  bid_late_1430_1457_p03_p97  \\\n",
      "0                         NaN                         NaN   \n",
      "1                         NaN                         NaN   \n",
      "2                         NaN                         NaN   \n",
      "3                         NaN                         NaN   \n",
      "4                         NaN                         NaN   \n",
      "\n",
      "   bid_close_1457_1500_p03_p97  bid_continue_930_1457_p03_p97  \n",
      "0                          NaN                            NaN  \n",
      "1                          NaN                            NaN  \n",
      "2                          NaN                            NaN  \n",
      "3                          NaN                            NaN  \n",
      "4                          NaN                            NaN  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_date = '2016-06-20'\n",
    "    end_date = '2025-05-31'\n",
    "    \n",
    "    # 定义时间段列表\n",
    "    time_intervals = [\n",
    "        'pre_open_915_920',\n",
    "        'pre_open_920_925',\n",
    "        'early_930_1000',\n",
    "        'main_1000_1430',\n",
    "        'late_1430_1457',\n",
    "        'close_1457_1500',\n",
    "        'continue_930_1457'\n",
    "    ]\n",
    "    \n",
    "    # # 定义因子类型\n",
    "    # factor_types = [\n",
    "    #     'bid_p01_p99',\n",
    "    #     'bid_p05_p95',\n",
    "    #     'ask_p01_p99',\n",
    "    #     'ask_p05_p95'\n",
    "    # ]\n",
    "\n",
    "        # 定义因子类型\n",
    "    factor_types = [\n",
    "        'bid_p03_p97',\n",
    "        'ask_p03_p97',\n",
    "    ]\n",
    "    \n",
    "    # 生成所有因子名称列表\n",
    "    all_factors = []\n",
    "    for factor_type in factor_types:\n",
    "        side = factor_type.split('_')[0]  # bid 或 ask\n",
    "        percentile = '_'.join(factor_type.split('_')[1:])  # p01_p99 或 p05_p95\n",
    "        for interval in time_intervals:\n",
    "            all_factors.append(f\"{side}_{interval}_{percentile}\")\n",
    "    \n",
    "    # 为每种因子类型创建单独的目录\n",
    "    factor_dirs = {}\n",
    "    for factor_type in factor_types:\n",
    "        factor_name = f\"3_97_percent_{factor_type}_price_divergence\"\n",
    "        factor_dir = f\"./factors/3_97_percent_price_divergence\"\n",
    "        factor_dirs[factor_type] = factor_dir\n",
    "        # print(f\"{factor_type} 因子文件已生成在目录: {factor_dir}\")\n",
    "        \n",
    "        # 统一化列名\n",
    "    # standardize_parquet_files(factor_dir)\n",
    "    \n",
    "    # 为每种因子类型计算滚动平均值\n",
    "    for factor_type, factor_dir in factor_dirs.items():\n",
    "        # 获取该类型的因子列表\n",
    "        type_factors = [f for f in all_factors if f.startswith(factor_type.split('_')[0]) and f.endswith('_'.join(factor_type.split('_')[1:]))]\n",
    "        \n",
    "        # 计算滚动平均\n",
    "        result_df = calculate_rolling_20d_avg(type_factors, factor_dir, start_date, end_date, min_window=5)\n",
    "        \n",
    "        # 保存结果为CSV\n",
    "        output_path = f\"/data/home/lexuanchen/Factors/Order/Signal/3_97_Percent_{factor_type.upper()}_Price_Divergence\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        print(f\"{factor_type} 因子共计 {len(result_df)} 条记录\")\n",
    "        print(\"\\n数据预览:\")\n",
    "        print(result_df.head())\n",
    "        \n",
    "        # 保存每个因子的CSV文件\n",
    "        for factor in type_factors:\n",
    "            output_file_path = f\"{output_path}/20d_{factor}.csv\"\n",
    "            factor_df = result_df[['date', 'security_code', factor]].dropna(subset=[factor])\n",
    "            factor_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/data/home/lexuanchen/Factors/Order/Signal/1_100_Percent_BID_P01_P99_Price_Divergence/bid_main_1000_1430_p01_p99.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(all_factor_data, factor_name, factor_type):\n",
    "    \"\"\"\n",
    "    筛选特定因子列且该列不为NaN的数据，并进行透视\n",
    "    \n",
    "    参数:\n",
    "    all_factor_data: 原始数据DataFrame\n",
    "    factor_name: 要筛选的因子列名称，例如'bid_pre_open_915_920_p01_p99'\n",
    "    \n",
    "    返回:\n",
    "    透视后的DataFrame，索引为date，列为security_code\n",
    "    \"\"\"\n",
    "    # 步骤1: 筛选必要的列\n",
    "    mask = all_factor_data['factor_type'] == factor_type\n",
    "    filtered_data = all_factor_data[mask][['date', 'security_code', factor_name]]\n",
    "    \n",
    "    # 步骤2: 去除因子列为NaN的行\n",
    "    filtered_data = filtered_data.dropna(subset=[factor_name])\n",
    "    \n",
    "    # 步骤3: 检查是否存在重复的(date, security_code)组合\n",
    "    duplicates = filtered_data.duplicated(subset=['date', 'security_code'], keep=False)\n",
    "    if duplicates.any():\n",
    "        print(f\"警告: 发现{duplicates.sum()}条重复记录，将保留第一条\")\n",
    "        # 如果有重复，保留第一条\n",
    "        filtered_data = filtered_data.drop_duplicates(subset=['date', 'security_code'], keep='first')\n",
    "    \n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在目录 ./factors/1_100_percent_bid_p01_p99_price_divergence 中找到 1534 个Parquet文件\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c8a3afe0fc40a49d885057b5f264a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/traitlets/traitlets.py(708): __set__\n  /tmp/ipykernel_972458/222077943.py(56): main\n  /tmp/ipykernel_972458/222077943.py(82): <module>\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3667): run_code\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3607): run_ast_nodes\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3362): run_cell_async\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/ipkernel.py(449): do_execute\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/ipkernel.py(362): execute_request\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(534): process_one\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/events.py(80): _run\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/base_events.py(1922): _run_once\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/base_events.py(607): run_forever\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/tornado/platform/asyncio.py(211): start\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelapp.py(739): start\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/traitlets/config/application.py(1075): launch_instance\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# 执行主函数\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m在目录 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfactor_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 中找到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(parquet_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个Parquet文件\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m conn = duckdb.connect(database=\u001b[33m'\u001b[39m\u001b[33m:memory:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     54\u001b[39m all_factor_data = conn.execute(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m    SELECT * FROM read_parquet(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparquet_pattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m).fetchdf()\n\u001b[32m     57\u001b[39m conn.close()\n\u001b[32m     60\u001b[39m all_factor_data[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(all_factor_data[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mError\u001b[39m: KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/traitlets/traitlets.py(708): __set__\n  /tmp/ipykernel_972458/222077943.py(56): main\n  /tmp/ipykernel_972458/222077943.py(82): <module>\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3667): run_code\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3607): run_ast_nodes\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3362): run_cell_async\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/ipkernel.py(449): do_execute\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/ipkernel.py(362): execute_request\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(534): process_one\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/events.py(80): _run\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/base_events.py(1922): _run_once\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/asyncio/base_events.py(607): run_forever\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/tornado/platform/asyncio.py(211): start\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel/kernelapp.py(739): start\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/traitlets/config/application.py(1075): launch_instance\n  /data/home/lexuanchen/.conda/envs/test1/lib/python3.11/site-packages/ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_date = '2016-06-20'\n",
    "    end_date = '2025-05-31'\n",
    "    \n",
    "    # 定义时间段列表\n",
    "    time_intervals = [\n",
    "        'pre_open_915_920',\n",
    "        'pre_open_920_925',\n",
    "        'early_930_1000',\n",
    "        'main_1000_1430',\n",
    "        'late_1430_1457',\n",
    "        'close_1457_1500',\n",
    "        'continue_930_1457'\n",
    "    ]\n",
    "    \n",
    "    # 定义因子类型\n",
    "    factor_types = [\n",
    "        'bid_p01_p99',\n",
    "        'bid_p05_p95',\n",
    "        'ask_p01_p99',\n",
    "        'ask_p05_p95'\n",
    "    ]\n",
    "    \n",
    "    # 生成所有因子名称列表\n",
    "    all_factors = []\n",
    "    for factor_type in factor_types:\n",
    "        side = factor_type.split('_')[0]  # bid 或 ask\n",
    "        percentile = '_'.join(factor_type.split('_')[1:])  # p01_p99 或 p05_p95\n",
    "        for interval in time_intervals:\n",
    "            all_factors.append(f\"{side}_{interval}_{percentile}\")\n",
    "    \n",
    "    # 为每种因子类型创建单独的目录\n",
    "    factor_dirs = {}\n",
    "    for factor_type in factor_types:\n",
    "        factor_name = f\"1_100_percent_{factor_type}_price_divergence\"\n",
    "        factor_dir = f\"./factors/1_100_percent_bid_p01_p99_price_divergence\"\n",
    "        factor_dirs[factor_type] = factor_dir\n",
    "        # print(f\"{factor_type} 因子文件已生成在目录: {factor_dir}\")\n",
    "        \n",
    "        # 统一化列名\n",
    "        # standardize_parquet_files(factor_dir)\n",
    "    \n",
    "    # 为每种因子类型计算滚动平均值\n",
    "    for factor_type, factor_dir in factor_dirs.items():\n",
    "        # 获取该类型的因子列表\n",
    "        type_factors = [f for f in all_factors if f.startswith(factor_type.split('_')[0]) and f.endswith('_'.join(factor_type.split('_')[1:]))]\n",
    "\n",
    "        parquet_pattern = os.path.join(factor_dir, \"*.parquet\")\n",
    "        parquet_files = glob.glob(parquet_pattern)\n",
    "        print(f\"在目录 {factor_dir} 中找到 {len(parquet_files)} 个Parquet文件\")\n",
    "        \n",
    "\n",
    "        conn = duckdb.connect(database=':memory:')\n",
    "        all_factor_data = conn.execute(f\"\"\"\n",
    "            SELECT * FROM read_parquet('{parquet_pattern}')\n",
    "        \"\"\").fetchdf()\n",
    "        conn.close()\n",
    "        \n",
    "\n",
    "        all_factor_data['date'] = pd.to_datetime(all_factor_data['date'])\n",
    "\n",
    "        all_factor_data = all_factor_data.sort_values(['date', 'security_code','factor_type'])\n",
    "\n",
    "        \n",
    "        # 保存结果为CSV\n",
    "        output_path = f\"/data/home/lexuanchen/Factors/Order/Signal/1_100_Percent_{factor_type.upper()}_Price_Divergence\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        print(f\"{factor_type} 因子共计 {len(result_df)} 条记录\")\n",
    "        print(\"\\n数据预览:\")\n",
    "        print(result_df.head())\n",
    "        \n",
    "        # 保存每个因子的CSV文件\n",
    "        for factor in type_factors:\n",
    "            result_df = filter_data(all_factor_data, factor, factor_type)\n",
    "            output_file_path = f\"{output_path}/raw_{factor}.csv\"\n",
    "            factor_df = result_df[['date', 'security_code', factor]].dropna(subset=[factor])\n",
    "            factor_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
