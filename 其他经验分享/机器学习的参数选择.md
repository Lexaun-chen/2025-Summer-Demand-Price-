### 找到一个模型的重要参数（提供最佳泛化性能的参数）的取值是一项棘手的任务，但对于几乎所有模型和数据集来说都是必要的。scikit-learn 中有一些标准方法。

#### 传统手工搜索
在传统的调参过程中，我们通过训练算法手动检查随机超参数集，并选择符合我们目标的最佳参数集。
![image](/uploads/90a81b55e7c63e1e685be662913bbc60/image.png)

**缺点：**

- 没办法确保得到最佳的参数组合。
- 这是一个不断试错的过程，所以，非常的耗时。

#### 简单网格搜索
网格搜索是一种基本的超参数调优技术。它类似于手动调优，为网格中指定的所有给定超参数值的每个排列构建模型，评估并选择最佳模型。考虑上面的例子，其中两个超参数 k_value =[2,3,4,5,6,7,8,9,10] & algorithm =[ auto ， ball_tree ， kd_tree ，brute ]，在这个例子中，它总共构建了9*4 = 36不同的模型。

让我们来了解一下sklearn的GridSearchCV是如何工作的：

![image](/uploads/e887e6e9cbfd1ee5b3636e34a0d89802/image.png)

在进行参数搜索时，我们应该将数据集分成训练集、验证集和测试集，其中，训练集用于构建模型，验证集（开发集）用于选择模型参数，测试集用于评估所选参数性能。
![image](/uploads/4829ca01d98a19a6cb613ae61279d1eb/image.png)

**缺点：**

由于它尝试了超参数的每一个组合，并根据交叉验证得分选择了最佳组合，这使得GridsearchCV非常慢。

**注意：**

在使用GridSearchCV 类时，我们需要建立字典。字典的键是我们要调节的参数名称，字典的值是我们想要尝试的参数设置。虽然GridSearchCV 使用了交叉验证，但是，我们仍需要将数据划分为训练集和测试集，以避免参数过拟合。这样我们分离出来的训练集X_train就可以作为GridSearchCV 的搜索数据了。拟合GridSearchCV 对象不仅会搜索最佳参数，还会利用得到最佳交叉验证性能的参数在整个训练数据集上自动拟合一个新模型。

#### 随机搜索
使用随机搜索代替网格搜索的动机是，在许多情况下，所有的超参数可能不是同等重要的。随机搜索从超参数空间中随机选择参数组合，参数由n_iter给定的固定迭代次数的情况下选择。实验证明，随机搜索的结果优于网格搜索。
![image](/uploads/3bb54a14c86011a22b05cf5388f3851e/image.png)

**缺点：**


随机搜索的问题是它不能保证给出最好的参数组合。

#### 贝叶斯搜索
贝叶斯优化属于一类优化算法，称为基于序列模型的优化(SMBO)算法。这些算法使用先前对损失 f 的观察结果，以确定下一个(最优)点来抽样 f。该算法大致可以概括如下。
1. 使用先前评估的点 X 1：n，计算损失 f 的后验期望。
2. 在新的点 X 的抽样损失 f，从而最大化f的期望的某些方法。该方法指定 f 域的哪些区域最适于抽样。

重复这些步骤，直到满足某些收敛准则。

![image](/uploads/9c8408ab3f877e0d0554e49878c0f7ce/image.png)

另一个实现贝叶斯搜索的类似库是`bayesian-optimization`。

**缺点：**

要在2维或3维的搜索空间中得到一个好的代理曲面需要十几个样本，增加搜索空间的维数需要更多的样本。

#### 总结
在确定参数的最佳组合的保证和计算时间之间总是存在权衡。如果超参数空间(超参数个数)非常大，则使用随机搜索找到超参数的潜在组合，然后在该局部使用网格搜索(超参数的潜在组合)选择最优特征。
